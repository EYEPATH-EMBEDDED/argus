# 파트 구성
1. WebSocket 핸들러:

    연결 시 세션별 메타데이터(시작 시간, 프레임 카운트)를 초기화

    메시지 타입에 따라 “이미지 처리” vs “종료 요청”을 분기

2. AI 모델 추론:
    collision_predictor 패키지를 불러와 프레임 단위로 process_frame() 실행

    결과(prob, is_collision)를 JSON 형태로 클라이언트에 푸시

3. 종료 후 부가 정보 전송:

    세션의 시작·종료 시간, 프레임 수를 취합해 REST API(또는 다른 WebSocket)로 전송

# 동작 흐름
1. 클라이언트가 ws://서버/ws로 연결하면 start_time 기록

2. 클라이언트는 메시지를 주기적으로 보냄

```json
{ "type": "image", "data": "<base64-encoded-jpg>" }
```

3. 서버는 predictor.process_frame() 호출 후 형태로 응답

```json
{ "type":"result", "frame_idx":123, "prob":0.456, "collision":false }
```


4. 사용을 마치고 종료할 때

```json
{ "type":"end", "session_id":"abc-123" }
```
메시지를 보내면, 서버는 집계된 start_time, end_time, image_count를 USAGE_REPORT_URL에 POST

5. POST 요청은 별도 스레드(executor)에서 비동기 실행 → 메인 루프 블로킹 방지

